# Redis key 知识点

## 1、key 过期策略 + 内存淘汰

redis 所有数据都是存储在 内存中的，内存很宝贵且有限，磁盘廉价且大量

由于 redis 的内存是有限的，因此不可能一直往 redis 中添加 key 而不进行处理，这样的话迟早会堆满整个内存空间

因此，对 key 的处理就显得至关重要了



我们需要知道，在 redis 当中，key 过期了如果没有删除的话仍然还是会占用内存的，因为过期仅仅只是一个标识符标识这个 key 不能再进行返回了而已，实际数据还是存在内存中的

因此，删除过期的 key 以及 当 redis 内存不足以存储新的 key 时的 处理方式 就显得格外重要



在此之前，我们需要先知道 **redis 中的一些存储 key 的数据结构：**

- expires 字典：存储了所有设置了过期时间的 key 以及对应的过期时间
- 键空间：保存了所有的 key（无论是否存在过期时间），expires 字典可以算作 键空间的一部分



> #### key 过期处理策略

- 定时删除：每个设置过期时间的 key 都会绑定一个专属的定时器，这样到达过期时间了就会立马删除过期的缓存 key
  - 该方法对内存很友好，因为会立即删除，不会占据内存，但是对 CPU 不友好，因为有 key 过期就需要 CPU 去处理，如果同一段时间过期的 key 量大，那么占用的 CPU 资源将会是巨大的
- 惰性删除：当一个 key 被访问时，才会判断该 key 是否已经过期，如果是，则删除。
  - 该方法对 CPU 友好，但是对 内存不友好，因为当大量过期的 key 没有被访问时，会一直占据着内存空间
- 定期删除：redis 默认每隔 100ms 就扫描 expires 字典，随机抽取一些  key，检查是否过期，如果过期了，那么删除
  - 该方法考虑 内存和 CPU 的权衡
  - 为什么不扫描整个 expires 字典？假设 redis 里面存放了 10W 个设置了过期时间的 key，每隔 100ms，就遍历 10W 个 key，这个是不现实的

**redis 使用的过期策略是 定期删除 + 惰性删除**



> #### 8 种 内存淘汰策略

 [彻底弄懂Redis的内存淘汰策略 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/105587132) 



redis 的内存空间是有限的，如果一直存储，那么总会挤满整个内存空间，单靠 key 过期处理策略是不行的

当要存储新的 key，而 redis 无法分配内存时，可以采取以下的策略：

1.  noeviction ：报错

2. **allkeys-lru**：移除掉 键空间 中最久没有使用的 key（LRU）

3. allkeys-random：随机移除掉 键空间 中的某个 key

4. volatile-lru：移除掉 expires 字典 中最久没有使用的 key（LRU）

5. volatile-random：随机移除掉 expires 字典 字典中的某个 key

6. volatile-ttl：在 expires 字典 中，优先移除掉过期时间距离现在最近的 key
7. volatile-lfu：从 expires 字典中删除使用频率最少的键（LFU）
8. allkeys-lfu：从键空间中删除使用频率最少的键（LFU）





## 2、key 三大问题：缓存雪崩、缓存穿透、缓存击穿



### 1、缓存雪崩

> #### 问题

缓存雪崩就是在**同一个时间段大量的 缓存 key 都失效了**，而这时大量的并发请求都打到 数据库上，导致数据库宕机



**举个简单的例子：**假设电商首页所有的 key 失效时间都是中午 12 点，即在 12 点会进行缓存的刷新，而在中午 12 点有个秒杀活动，并发量会非常高，假设每秒 1W 请求，本来 redis 能够命中率 80%，那么最终只有 2000 个请求会打到 db 上，db 扛得住。但是由于 redis 所有的 key 都失效了，那么就会导致这 1W 个 key 全部打到数据库上，可能会导致数据库直接宕机（后续所有的请求都超时），而其他所有依赖这个数据库的接口全部瘫痪，用户体验极差

![img](https://pic4.zhimg.com/80/v2-e6e23ac28b0915c0fae67b5d6da34277_720w.jpg)



> #### 解决

1、由于是同一时间大量 key 失效才会造成这个问题，那么我们只需要将 key 的失效时间错开就可以了

在设置 key 的失效时间时加上一个随机值，这样可以保证在同一段时间内不会出现大面积 key 失效的情况

```C
setRedis（Key，value，time + Math.random() * 10000）；
```

2、设置热点数据永不过期，定期异步更新（**刷新缓存的时候加锁，此时会存在一段时间的数据不一致**）

3、先从 redis 读，当数据不存在时，那么由一个线程加锁，从 db 读，然后更新数据到 redis 中，其他线程阻塞在加锁处，保证只有一个线程更新缓存（双重检查，这里问题在于比如存在 1000 个请求，那么只有一个线程在执行，会阻塞剩下的其他线程，导致响应时间增加）



### 2、缓存穿透

> #### 问题

缓存穿透就是 **用户不断请求数据库中没有的数据，这样就必定不会走缓存，使得请求直到打到数据库上**



比如 数据库表 id 是从 1 自增上去的，这样的话用户不断请求 id = -1 的数据，就可以直接绕过缓存，打到数据库

这样的用户很可能就是攻击者了，一旦并发量高，数据库可能直接宕机

![img](https://picb.zhimg.com/80/v2-e846d8c3371c5eef80cf4185bcec15c4_720w.jpg)

> #### 解决

- **对参数进行校验**，上面的 id = -1 明显是不可能存在的参数，因此需要进行校验，而有的情况下需要接收分表查询的参数，类似这种的也需要校验，因为前端发过来的不一定都是合法参数，可能是攻击者之类发的，要是最大为 max = Integer.MAX_VALUE，那么数据库表数据量一大，每次查询都要几秒，这样问题就大了，这种请求明显是攻击的，因此可以直接舍弃掉
- **限制每个 ip 每秒可以发送的请求数**，比如我们点击某个按钮，一般频繁点击的话会说操作频繁，稍后再试（不过对于攻击者来说没啥实际作用，攻击者可以用不同的 ip 发起攻击）
- 对于第一次查询不存在的数据，我们 **缓存空对象 null**
  - 由于可能很多请求的数据会不存在，所以可能需要在 redis 大量缓存空对象，这样就会导致内存大量占用
- 最好的方法就是**使用 布隆过滤器**，它能够判断哪些数据必定是不存在的，哪些数据是可能存在的，对于必定不存在的数据我们就没必要去查询数据库
  - 布隆过滤器底层是 bitmap，经过多次 hash 得到一串二进制数，将每个数映射到这个 bitmap 上
  - 布隆过滤器的缺点就是只能增加不能删除，并且一旦布隆过滤器添加的数据量变大，那么将会导致很多 bit 位置都为 1，那么导致误判的可能性也会随之提高





### 3、缓存击穿

> #### 问题

缓存击穿 有点像 缓存雪崩，但是缓存雪崩指的是不同的 key 大面积失效，而 缓存穿透 指 一个非常热点的 key 在失效的时候，高并发不断对这个 key 进行访问，导致全部打到数据库中

由于只是一个 key 失效导致的问题，就跟一颗子弹直接击穿然后出现一个洞一样

<img src="https://pic2.zhimg.com/80/v2-102c103361db026414237c4be9de2ec9_720w.jpg" style="zoom:50%;" />



> #### 解决

（这里的操作跟缓存雪崩一样，只不过少了设置 key 失效时间随机数而已）

1、设置热点 key 永不过期，定期异步更新（**刷新缓存的时候加锁，此时会存在一段时间的数据不一致**）

2、先从 redis 读，当数据不存在时，那么由一个线程加锁，从 db 读，然后更新数据到 redis 中，其他线程阻塞在加锁处，保证只有一个线程更新缓存（双重检查，这里问题在于比如存在 1000 个请求，那么只有一个线程在执行，会阻塞剩下的其他线程，导致响应时间增加）





## 3、缓存数据库一致性问题（缓存双写问题）

**使用缓存就必定会存在数据不一致的问题**，**我们不要求数据强一致，只要求数据最终一致性**

这里探讨的数据一致性，是说由于某些错误操作导致的 **长时间** 的 db 和 redis 的不一致，而不是像上面这种 key 永不过期，定期异步更新过程中 **短暂 **的不一致



### 1、先更新数据库，再删除缓存

有以下情况

1、更新数据库失败，那么不删除缓存，此时 db 和 redis 数据一致，请求获取的仍然是旧值，没问题

2、更新数据库成功，删除缓存失败，此时 db 和 redis 数据不一致，请求获取的是 redis 的旧值，但是数据库中存在新值，如果缓存删除失败然后没有后续处理的话，那么将会导致 db 和 redis **长时间** 的数据不一致，因此删除缓存失败需要进行重试

3、更新数据库成功，删除缓存成功，下次请求查询缓存的时候发现缓存为空，从数据库中获取，然后更新到缓存中，db 和 redis 数据一致，都是新值，没问题（这里线程查询数据库前需要加锁，使用双重检查，避免多个请求同时访问数据库）



### 2、先删除缓存，再更新数据库

有以下情况：

1、删除缓存失败，那么不更新数据库，那么 db 和 redis 中都是旧值，保证了数据一致性，没问题

2、删除缓存成功，更新数据库失败，那么 redis 没有值，数据库中的是旧值，下次请求发现缓存没有值去数据库读取，然后更新缓存，db 和 redis 都是旧值，数据一致性，没问题（这里使用双重检查 DCL）

3、删除缓存成功，更新数据库成功，请求查询缓存没有值，从数据库获取，更新缓存，db 和 redis 都是新值，数据一致性，没问题（这里使用 DCL）



然而实际上这种方法在多线程情况下还是会存在问题：

1. 线程 A 删除了缓存

2. 线程 B 获取缓存发现为 null，那么就查询数据库，然后将数据库旧值存储到缓存中

3. 线程 A 更新数据库

同时来了两个线程 A 和 B，线程 A 访问 update 接口，先删除了缓存，此时线程 A 更新数据库的，与此同时在线程 A 更新数据库前，线程 B 访问 get() 接口，发现缓存为空，那么读取数据库，将结果更新到缓存中，然后线程 A 才更新数据库完成，这样的话数据库的是新值，缓存中的是旧值，将会导致 **长时间** 的数据不一致。



### 3、延时双删

为了解决 2 中的多线程可能出现的数据不一致问题，这里出现延时双删方案



线程 A 删除完缓存后，更新完数据库，然后 sleep 睡眠一段时间，然后再删除缓存

sleep 的目的是为了删除线程 B 存储到缓存中的旧值

（在睡眠的这段时间内存在数据不一致的问题）

```java
public static void main(string[] args) {
    redis.del()
    db.update()
    Thread.sleep(500);
    redis.del()
}
```

这种方案的缺点也很明显：难以估计睡眠时间，如果 sleep 时间短，那么此时线程 B 可能只是查询完数据库，还没有更新到缓存中，如果 sleep 时间长，那么将会导致线程 A 处理的请求响应时间增加（这里也可以选择开另一个线程去 sleep 然后删除缓存）



### 4、基于 binlog 的异步更新（最优）

数据库对每条写操作都会生成对应的 binlog，并且它是确保了一定的顺序的，即谁先执行那么谁就先生成 binlog

假设同时存在两个线程 A 和 C，它们要对同一条数据进行写操作

如果线程 A 先修改了 数据行 x，线程 C 后修改 数据行 x，那么线程 A 会比 线程 C 更早生成 binlog

因此，可以开一个进程订阅数据库的 binlog ，当该进程执行 binlog 的话，由于线程 C 的 binlog 在线程 A 的 binlog 后面，因此进程会先执行线程 A 的 binlog，那么线程 C 的 binlog 的更新数据会覆盖掉 线程 A 的 binlog 的更新数据，最终保证了 db 和 redis 的数据一致性



MySQL binlog 增量订阅消费 + 消息队列 + 增量数据更新到redis

**1）读在 Redis**：热数据基本都在 Redis

**2）写在 MySQL**：增删改都是操作 MySQL

**3）更新 Redis 数据**：通过 MySQL binlog 来异步更新 Redis



热点 key 缓存在 redis 中，并且设置为永不过期，当 mysql 写操作完成后发布 binlog 异步更新缓存

由于 redis 不删除缓存，那么线程 B 对于热数据的读取都不会去读取数据库，那么就不会发生将旧数据更新到缓存的情况。

并且这样只是存在短暂的数据不一致性，而不会存在长时间的数据不一致性，很保险。