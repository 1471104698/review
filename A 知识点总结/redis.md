# Redis 总结



## 1、Redis 基本数据结构

redis 自定义了一个核心数据结构：redisObject

![img](https://picb.zhimg.com/80/v2-92afb6f1dd844e640fe40c242dede27d_720w.jpg)

redisObject 主要由 3 部分组成：type、encoding、ptr

type 存储当前 redisObject 实例对应的基本数据类型

encoding 存储基本数据类型对应的编码格式

ptr 是指向真实数据的指针



基本数据类型：string、list、hash、set、zset

1、string

```c
编码格式有 int、embstr、raw（其中 embstr、raw 是 SDS 结构）
当只有数字的时候，使用 int
当字符串长度 <= 39B 时，使用 embstr，此时 redisObject 和 SDS 同时分配，是一段连续的内存
当字符串长度 > 39B 时，使用 raw，redisObject 和 SDS 两次分配

type SDS struct {
    // 已经使用的长度
	len int
    // 可以使用的长度
	free int
    // 存储的字符串
	data char[]
}
```

2、list

```c
编码格式有：ziplist、linkedlist、quicklist
```

3、hash

```
编码格式有：ziplist、dict

dict，类似 hashMap，不过内部维护了两个 hashTable，用于渐进式 rehash（）
```

4、set

```
编码格式有：intset、dict
当元素只有数字时，使用 intset，它是一个有序 int 数组，每次需要先插入二分查找，然后将后面的元素后移插入
当元素存在字符或者元素个数超过一定限制时，使用 dict，这里类似 HashSet 的做法，底层使用 HashMap 实现
```

5、zset

```
编码格式有：linkedlist、dict+skiplist

dict 用于 O(1) 查找，skiplist 用于范围查找，dict 和 skiplist 使用同一份节点
skiplist O(logn) 查找效率
```



## 2、redis 的 skiplist

### 1、和传统的 skiplist 的区别

传统的 skiplist：简单的 O(logn) 查找



redis 的 skiplist 是根据传统 skiplist 进行修改的，为了方便一些排名之类的获取

skiplist 结构：

```c
typedef struct zskiplistNode {
    robj *obj;		// member，指向的是 string，排序的第二依据
    double score;	// score，排序的第一依据
    struct zskiplistNode *backward;	 	// 指向前驱节点的指针（这也是跟传统 skiplist 不一样的地方，双向链表）
    struct zskiplistLevel {
        struct zskiplistNode *forward;	// 每层中指向后继节点的指针
        unsigned int span; // 当前节点与后继节点 forward 之间的元素个数,用来 rank 排名（同一列的节点它们的后继节点可能不同，所以 span 值也会不同）
    } level[];
} zskiplistNode;

typedef struct zskiplist {
    struct zskiplistNode *header, *tail;	// 跳跃表头节点和尾节点
    unsigned long length; 					// 跳跃表中元素个数
    int level;								// 跳跃表当前最大层数
} zskiplist;
```



> ####  redis 的 skiplist 的三个优化点：

1、redis 的 skiplist 是一个双向链表，这是为了方便倒序查找，比如 skiplist 维护了 100 个元素，要找 rank = 98 的元素，那么从后往前找第二个元素即可

2、每个节点都维护了一个 span 字段，用来存储与前驱节点的距离，这是为了 rank 计算：

```c
h1		b1
h2	a1	b2			e1
h3	a2	b3	c1		e2
h4	a3	b4	c2	d1	e3  d1
h5	a4	b5	c3	d2	e4  d2
    
h1 与 b1 中间有 1 个元素，所以 h1 与 b1 的距离为 2，即 h1.span = 2
b1 没有后继节点，所以 b1.span = 0
同理 
    h2.span = 1, a1.span = 1, b2.span = 3, e1.span = 0
    h3.span = 1, a2.span = 1, b3.span = 1, c1.span = 2, e1.span = 0
    .....
比如我们要查找 d1 对应 member 的排名（d1 和 d2 的 member 是一样的）
    那么我们先从 h1 出发，到达 b1，那么 rank += h1.span
    rank = 2
    由于 b1 没有后继节点，因此再从 b1 到达 b2，再从 b2 到达 e1，那么 rank += b2.span， 
    rank = 5
    由于 e1 没有后继节点，那么一直往下，直到 e4
    从 e4 到达 d5，那么 rank += e4.span
    rank = 6
    找到目标节点，完成搜索，那么 rank 就是 d1 的 member 排名
```

3、排序优化：传统的 skiplist 中，如果插入的所有 member 对应的 score 都相同，那么如果仅仅根据 score 来排序的话，实际上这些节点就变成了无序的了，那么查询效率就从 O(logn) 转变成 O(n)。因此，redis 的 skiplist 为了防止这种问题进行了处理：当 score 相同时，根据 member 对应的字符串来按照字典序来进行排序



### 2、为什么不使用 B+ 树

mysql 使用 B+ 树是因为数据存储在磁盘上，需要考虑到磁盘IO的次数，想尽可能存储更多的数据并且减少查找时的磁盘 IO 次数，B+ 树是叶子节点存储真实数据，其他节点存储索引值，像这种情况每个非叶子节点可以存储更多的索引值，这样的话每层相比 B树 可以存储更多的索引值，以此来减少树的高度



redis 是内存数据库，不需要涉及到磁盘IO，redis 的 skiplist 实现为双向链表，支持倒叙查询，同时每个节点还维护了一个 span 字段，方便用于排名查询，同时 redis 的数据结构相比 B+ 树来讲较为简单，redis 作者由于 redis 结构的简单而收到了一个补丁，同时已经应用该补丁。



## 3、Redis key 清除策略

redis 有 键空间 和 expires 字典

- 键空间存储的是所有的 key

- expires 字典存储的是设置了过期时间的 key，即 expires 字典算是键空间的一部分



1、当 key 过期时，那么通知 redis 去删除

```
对内存友好，但是对 CPU 资源不友好
```

2、定期扫描 expires 字典，选择一部分的 key，将这部分 key 中过期的 key 删除

```
对 CPU 友好，对内存不友好
```

3、惰性删除，key 过期了不立即处理，只有当访问到该 key 时，发现过期了再删除



redis 使用的是 定期扫描 + 惰性删除，权衡时间和空间



## 4、Redis 缓存淘汰策略

```
1、从键空间中随机选择 key 删除
2、从 expires 字典中随机选择 key 删除
3、从键空间中移除最近没有使用的 key（LRU）
4、从 expires 字典中移除最近没有使用的 key（LRU）
5、报错
6、从 expires 字典中移除最快要过期的 key

7、从键空间中移除最近使用频率最少的 key（LFU）
8、从 expires 字典中移除最近使用频率最少的 key（LFU）
```



## 5、Redis 缓存三大问题

### 1、缓存雪崩

背景：

同一时间大面积的 key 失效，此时来了大量请求，缓存失效不命中，全部打到 DB 上，导致 DB 宕机



解决：

①、在设置缓存过期时间时，添加一个随机值，让它们的失效时间分散开来

②、使用 DCL，第一个线程读取缓存为空时加锁，访问 DB，更新缓存，其他线程在加锁阶段进行阻塞，避免多个线程同时访问 DB，注意：如果这里没有数据了，那么可以选择缓存空对象，避免其他线程也发现没有数据都去访问 DB

③、缓存不直接设置过期时间，在设置时多加一个字段，用于标识它的过期时间，线程访问时获取它的过期时间，如果过期了那么加锁，访问 DB，更新缓存，其他线程没有获取到锁时不阻塞，直接获取旧数据返回，这里会存在短暂的数据不一致，但是最后会达到最终数据一致性



（如果是集群环境，那么这里的锁需要使用分布式锁）

```
方案二可以跟方案三一样没有获取到锁的线程直接不阻塞吗？
不可以，因为方案三是存在旧数据的，其他线程可以获取旧数据返回，而方案二没有旧数据缓存，其他线程如果不阻塞的话，那么将会返回空数据，但是 DB 中可能是存在数据的，这里返回旧数据和返回空数据两者在业务上差别就很大了
```



### 2、缓存击穿

背景：

一个热点 key 缓存失效，大量请求来访问这个 key，缓存失效绕过缓存，全部打到 DB 上，导致 DB 宕机



解决：

参考缓存雪崩的方案二和方案三



### 3、缓存穿透

背景：

用户一直访问不存在的数据，缓存不命中，直接将请求打到 DB 上，

比如数据库 ID 从 1 开始自增，但是用户访问 ID = -1 的数据，缓存不命中，导致直接请求 DB

**这种要防止的是攻击**



解决：

1、**参数校验**：对于 ID = -1 这种明显不存在的数据，可以直接忽略掉，在分页情况下，limit = maxInt32，这种不合理的参数值明显是带有攻击性的，也可以直接忽略掉

2、**限制 IP 每秒请求次数**：限制每个 IP 每秒的请求次数，比如我们某个按钮，多次点击后会显示 **操作繁忙，稍后再试** 之类的，不过这种对于预防攻击可能很难生效，因为攻击者可以伪造 IP

3、**DCL + 缓存空对象**：第一个线程访问缓存不命中时加锁，然后访问 DB，如果数据不存在，那么缓存空对象，那么其他线程访问缓存时会获取这个空对象，从而避免访问 DB

4、**布隆过滤器**：可以使用 redis 的 bitmap 实现，对于某个 key 通过多个散列算法计算出多个 hash 值，将每个 hash 值作为索引，将 bitmap 对应索引位置上的 bit 置 1。当线程访问一个 key 时，对 key 使用相同的散列计算得到多个 hash 值，然后一个个判断 bitmap 对应索引位置上是否为 1，如果全为 1，那么 key 可能存在，如果存在一个为 0，那么 key 必定不存在。这样可以避免必定不存在的数据的无效访问

- 缺点：布隆过滤器只能增加数据，不能删除数据，因为上面的每个 bit 可能是多个 key 共用的，同时如果增加的数据量多了，那么 bitmap 上很多位置都被置 1，那么误判的概率就会增加



## 6、DB 和 缓存双写

DB 和 缓存要求的是最终一致性，允许它们存在短暂的数据不一致问题



### 1、先更新 DB，再删除缓存

有以下几种情况：

①、更新 DB 失败，那么不删除缓存，此时 DB 和 缓存都是旧值，没问题

②、更新 DB 成功，删除缓存失败，此时 DB 是新值，缓存是旧值，这样直到缓存过期前都存在数据不一致性问题，因此存在问题，这里可以使用删除重试，直到删除成功为止

③、更新 DB 成功，删除缓存成功，下次线程读取会从 DB 中获取新值更新到缓存中，没问题



```
为什么是删除缓存，而不是更新缓存？

缓存的计算可能是需要跨多个表的或者需要经过比较复杂的计算，在写多读少的情况下，如果每次修改都去更新缓存，并且此次缓存更新后还没有线程访问就又重新进行写操作，那么又要更新缓存，那么上一次缓存更新操作将是无效操作
因此直接删除缓存，当线程来访问时才更新缓存
```



### 2、先删除缓存，再更新 DB

有以下几种情况：

①、删除缓存失败，不更新数据库，那么缓存和数据库都是旧值，没问题

②、删除缓存成功，更新数据库失败，那么下次线程访问的是 DB 中的旧值，没问题

③、删除缓存成功，更新数据库成功，没问题



这种方案看似完美，但实际上在高并发情况下可能会出现以下情况：

```
线程 A 和 线程 B 同时到达，线程 A 写操作，线程 B 读操作，都是操作的同一个 key
线程 A 删除缓存后还没更新 DB ，线程 B 发现缓存不命中，从 DB 中读取到旧值，更新到缓存中，然后 线程 A 才更新数据库
这将导致 缓存 和 DB 长时间的数据不一致
```



### 3、延时双删

对于上面的问题，使用延时双删方案：

1. 线程 A 删除缓存
2. 线程 B 访问数据库获取旧值
3. 线程 B 更新旧值到缓存
4. 线程 A 更新新值到 DB
5. 线程 A sleep() 一段时间
6. 线程 A 再次执行删除缓存



这里线程 A 更新完 DB 后会进行一段休眠，目的是等待其他线程将访问到的旧值存储到缓存中，然后休眠结束后将缓存中的旧值删除

这个方案问题在于对休眠时间难以把控：

```
休眠时间设置过短，那么可能 线程 B 还没有将 旧值更新到缓存中
休眠时间过长，那么导致请求响应时间增加（当然这里可以开一个线程去单独执行 休眠+删除 操作，不过该方案不是最优解）
```



### 4、基于 binlog 的异步更新

DB 的 binlog：

```
mysql 对于每个写操作都会生成一条 binlog 日志，用来记录当前执行了什么写操作，并且 binlog 是按照写操作执行的先后顺序来存储的，比如 线程 A 先修改了数据 X，线程 C 后修改了数据 X，那么 binlog 会先生成 线程 A 的 binlog，再生成 线程 C 的 binloig
```



因此，缓存不设置过期时间，然后开一个进程去订阅 mysql 的 binlog，然后根据 binlog 的顺序去异步更新缓存

线程 A 比 线程 C 先执行修改操作，那么 DB 中数据 X 的最新值就是 线程 C 修改的值，同时 线程 A 比 线程 C 先生成 binlog，那么进程在订阅执行 binlog 时，会先执行 线程 A 的 binlog，然后再执行 线程 C 的 binlog，那么这样就保证了缓存中的最新值是 线程 C 修改的值

同时这里由于缓存不设置过期时间，那么就不存在 线程 B 去读取 DB 旧数据然后更新到缓存中的问题了





## 7、IO 多路复用

```java
1、IO 多路复用是什么？
	IO 多路复用是 IO 模型的一种
    在没有 IO 多路复用的情况下，我们只能使用 BIO 或者 NIO，它们都需要给每个 socket 分配一个线程，线程资源占用大。
    而 IO 多路复用 则是使用一个线程来管理多个 socket 的读写、连接等事件。

常见的 IO 多路复用模型有：select、poll、epoll

2、select：
select 使用的数据结构是 long 型数组 fd_set，实际上是当作 bitmap 来使用的
它维护了 3 个 fd_set，read_fd、write_fd、listen_fd 分别对应 读事件、写事件、accept 事件
每个 bit 位置的下标对应 fd，比如 read_fd[10] = 1 表示监听 fd = 10 的 socket 的读事件

select 执行流程：
    1）进程关心哪些 socket 以及对应的事件，就将对应 fd_set 上对应位置的 bit 置为 1
    2）调用 select()，将 fd_set 作为方法参数传入到内核中
    3）内核拷贝 3 个 fd_set，然后进行 O(n) 轮询，它只会去查看 fd_set 上 bit = 1 的 socket,对于 bit = 0 的 socket 进程并不关心，那么内核也不会去查看
    4）轮询过程中，内核将没有发生对应事件的 bit 置为 0，同时记录发生了事件的 socket 个数 n，当全部轮询完毕后，将 fd_set 拷贝回用户态，并且 n 返回给用户态进程
    5）用户态进程根据 n 对 fd_set 进行轮询，如果 bit = 1，那么进行处理

需要注意的是，select() 每次调用前都需要重置 fd_set 中的 bit，否则 fd_set 中的数据就是被内核修改过的数据

select 的缺点：
    1）每次调用 select() 都需要将 fd_set 拷贝到内核态中，同时内核态还需要 O(n) 去轮询这些 fd_set，轮询完毕后还需要将 fd_set 拷贝回内核态
    2）内核并没有准确告知用户进程哪些 socket 发生了事件，只是将发生事件的 socket 个数告知用户进程，因此用户进程同样也需要 O(n) 去轮询这些 fd_set
    3）select 的 fd_set 由于内核的原因，只支持 [0, 1023] 索引位置的 fd，即表示 select 只能处理 1024 个 socket，超过该范围的 socket 无法正常处理
即一次 select() 需要 两次 copy 和 两次 O(n) 轮询，效率低下

3、poll:
poll 舍弃了 select 的 fd_set，而使用了链表的形式，这样就不会限制只能处理 1024 个 socket。
其他的方式跟 select 一样


4、epoll：
epoll 开启了新的模式，不再是由用户进程来管理 socket， 而是由内核来管理 socket
epoll 定义了三个函数：
    1）int epoll_create()
    2）int epoll_ctl(int epfd, int op, int fd, epoll_event *event)
    3）int epoll_wait(int epfd, epoll_event *events, int maxevents, int timeout)

epoll 内部使用一个红黑树来管理所有的 fd，使用一个 rdlist(ready list) 就绪链表来存储存在事件的 fd：
    1）当用户进程调用 epoll_create() 那么会创建一个 epoll 对象
    2）当用户进程调用 epoll_ctl() 添加一个新的 fd 时，会同时根据监听的事件注册一个回调函数 ep_poll_callback() 到网卡设备上，当发生监听的事件时，会调用这个回调函数将 fd 加入到 rdlist 中
    3）当用户进程调用 epoll_wait() 的时候，如果 rdlist 中存在节点，那么将 rdlist 中的 fd 以及对应的事件 拷贝到用户进程，用户进程只需要轮询这些节点即可；如果 rdlist 为空，那么用户进程会进入等待队列中等待，如果在等待期间有 fd 发生事件，调用了回调函数，那么回调函数在将 fd 放入 rdlist 后会唤醒用户进程；如果等待超时，那么直接返回
    
关于 epoll_wait() 是否会发生拷贝：
	在 epoll_wait() 源码里面有个 put_user()，表示将 epoll_event 拷贝到用户态进程，因此是发生了拷贝的
    而且调用 epoll_wait() 时需要传入一个 epoll_event 指针，这是用户进程开辟的内存，这也表示了是需要发生拷贝的
	它并没有使用 mmap 共享内存来减少拷贝（很多文章都是说使用共享内存的方式来减少拷贝，这是错的，至少源码没体现）
	
epoll 相比 select 的优点：
    1）epoll 由内核来管理 socket，省去了 select 数据结构 fd_set 的用户态和内核态之间的拷贝
    2）epoll 通过回调函数的机制以及将发生事件的 fd 和 对应的事件直接拷贝到内核态，省去了内核和用户进程 O(n) 轮询的时间
    3）select 和 poll 只支持 LT，而 epoll 支持 LT 和 ET

epoll 的两种触发方式：
1）水平触发 LT： 如果按照电平来说，那么只要位于高电平就会触发
    可读事件：如果 socket 接收缓冲区存在数据，那么就会触发可读事件
    可写事件：如果 socket 发送缓冲区未满，那么就会触发可写事件

2）边缘触发 ET: 如果按照电平来说，那么只有从低电平变为高电平的时候才会触发
    可读事件：只有接收到新的数据才会触发可读事件
    可写事件：
            socket 发送缓冲区状态变化： 满-> 未满，触发一次可写事件
            epoll_ctl() 注册可写事件（无论是新添加 fd 还是 重新注册监听事件），触发一次可写事件
            同时监听读写事件，当可读事件发生时，如果发送缓冲区未满，那么会顺带一个可写事件
            
对于 ET，如果可读事件触发后没有一次性全部读取完毕，那么也不会再触发可读事件，因为在 epoll_wait() 中当拷贝到用户进程后会将该 fd 从 rdlist 中移除，而 LT 则是会继续存储到 rdlist 中。
所以 ET 在必要的情况下需要使用 while 读取完所有的数据，同时要设置 非阻塞，避免读取完数据后阻塞在 read() 处


LT 和 ET 之间的区别：
ET 是用来减少一些不必要事件的频繁触发，防止浪费 CPU 资源
    LT 的可读事件：不需要一次全部读取完成，因为下次还是会在 rdlist 中，可以留到下次读取
    ET 的可读事件：一般需要使用 while 循环读取，否则可能会导致数据堆积，而 while 读取需要将 fd 设置为非阻塞，防止数据读取完毕后阻塞在 read() 处
    LT 的可写事件：如果在不需要写数据的情况，那么需要将可写事件移除掉，否则会频繁触发
    ET 的可写事件：如果可写事件触发后，有的数据还没有处理完成，无法此时写入时，那么可以在数据处理完成后重新注册监听可写事件，以此来触发可写事件，然后将处理完的数据写入
```

